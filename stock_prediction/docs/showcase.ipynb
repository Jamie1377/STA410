{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction Framework Demo\n",
    "### This notebook demonstrates the end-to-end functionality of the stock prediction system using predictor.py and models.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is a sample code for the STA410 course at the University of Toronto.\n",
    "# # It is not meant to be run as a standalone script.\n",
    "# # It is meant to be run in a Jupyter notebook.\n",
    "# # You can install the package usaing pip:\n",
    "# %pip install stock-prediction-sta410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core modules\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from sklearn.metrics import r2_score\n",
    "import yfinance as yf\n",
    "\n",
    "# Import custom modules\n",
    "from stock_prediction.core import StockPredictor\n",
    "\n",
    "# Energy sector companies\n",
    "energy_sector = yf.Sector(\"energy\").top_companies.index\n",
    "technology_sector = yf.Sector(\"technology\").top_companies.index\n",
    "symbol= 'UBER' \n",
    "\n",
    "# Initialize predictor with example parameters\n",
    "print(f\"Selected symbol: {symbol}\")\n",
    "start_date = \"2023-06-01\"\n",
    "end_date = date.today()\n",
    "\n",
    "# Day trading\n",
    "# predictor = StockPredictor(\n",
    "#     symbol=symbol, start_date=date.today()-pd.Timedelta(days=1), end_date=date.today()+pd.Timedelta(days=1),  interval=\"1m\"\n",
    "# )\n",
    "\n",
    "# Short term trading\n",
    "predictor = StockPredictor(\n",
    "    symbol=symbol, start_date=start_date, end_date=end_date, interval=\"1d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.trading.requests import MarketOrderRequest\n",
    "from alpaca.trading.enums import OrderSide, TimeInForce, QueryOrderStatus\n",
    "trading_client = TradingClient('UR_API_KEY', 'UR_SECRET_KEY', paper=True)\n",
    "trading_client.get_all_positions()\n",
    "\n",
    "try:\n",
    "    account = trading_client.get_account()\n",
    "    print(f\"Connected to {account.account_number}\")\n",
    "    print(f\"Buying Power: {account.buying_power}\")\n",
    "    print(f\"Trading Blocked: {account.trading_blocked}\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {str(e)}\")\n",
    "    raise\n",
    "account = trading_client.get_account()\n",
    "float(account.equity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca.trading.enums import QueryOrderStatus\n",
    "from alpaca.trading.requests import GetOrdersRequest\n",
    "orders = trading_client.get_orders(filter=GetOrdersRequest(status=QueryOrderStatus.OPEN))\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEt the available stock on the market\n",
    "from alpaca.trading.requests import GetAssetsRequest\n",
    "assets = trading_client.get_all_assets(filter=GetAssetsRequest(status=\"active\", asset_class=\"us_equity\"))\n",
    "[asset for asset in assets if asset.symbol == 'AXP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_client.get_all_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca.data.historical import StockHistoricalDataClient, CryptoHistoricalDataClient\n",
    "from alpaca.data.requests import CryptoSnapshotRequest\n",
    "data_client = CryptoHistoricalDataClient(api_key='UR_API_KEY', secret_key='UR_SECRET_KEY')\n",
    "req = CryptoSnapshotRequest(symbol_or_symbols='XRP/USD')\n",
    "data_client.get_crypto_snapshot(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca.data.requests import StockLatestTradeRequest\n",
    "data_client2 = StockHistoricalDataClient(api_key='UR_API_KEY', secret_key='UR_SECRET_KEY')\n",
    "data_client2.get_stock_latest_trade(StockLatestTradeRequest(symbol_or_symbols='AAPL'))['AAPL'].price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set([stock.symbol for stock in trading_client.get_orders(\n",
    "            filter=GetOrdersRequest(status=QueryOrderStatus.OPEN)\n",
    "        )]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_client.get_orders(\n",
    "            filter=GetOrdersRequest(status=QueryOrderStatus.OPEN)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load and prepare data\n",
    "predictor.load_data()\n",
    "df = predictor.data\n",
    "\n",
    "# Display processed data\n",
    "print(\"\\nProcessed Data with Features:\")\n",
    "features = (\n",
    "    [\n",
    "        # \"Market_State\",\n",
    "        \"Close\",\n",
    "        \"MA_50\",\n",
    "        # \"MA_200\",\n",
    "        \"High\",\n",
    "        \"Low\",\n",
    "        \"MA_7\",\n",
    "        \"MA_21\",\n",
    "        \"SP500\",\n",
    "        # \"TNX\",\n",
    "        \"USDCAD=X\",\n",
    "        \"Tech\",\n",
    "        \"Fin\",\n",
    "        \"VIX\",\n",
    "        \"Energy\",\n",
    "        # \"Fourier_PCA_0\",\n",
    "        # \"Fourier_PCA_1\",\n",
    "        # \"FT_real\",\n",
    "        # \"FT_img\",\n",
    "        # \"Market_State\",\n",
    "        # \"Market_Sentiment\",\n",
    "    ]\n",
    "    + [\n",
    "        \"rolling_min\",\n",
    "        \"rolling_median\",\n",
    "        \"rolling_sum\",\n",
    "        \"rolling_ema\",\n",
    "        \"rolling_25p\",\n",
    "        \"rolling_75p\",\n",
    "    ]\n",
    "    + [\"RSI\", \"MACD\", \"ATR\", \"Upper_Bollinger\", \"Lower_Bollinger\"]\n",
    "    + [\"VWAP\"]\n",
    "    + [  # \"Volatility\",\n",
    "        \"Daily Returns\",\n",
    "        \"Williams_%R\",\n",
    "        \"Momentum_Interaction\",\n",
    "        # \"Volatility_Adj_Momentum\",\n",
    "        \"Stochastic_%K\",\n",
    "        \"Stochastic_%D\",\n",
    "        \"Momentum_Score\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(df[features].tail())\n",
    "print(df[features].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_prediction.core.models import ARIMAXGBoost\n",
    "from lightgbm import LGBMRegressor \n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from stock_prediction.utils import optimize_lookback\n",
    "# Scale the features\n",
    "lookback = optimize_lookback(\n",
    "    df[features],\n",
    "    df[\"Close\"],\n",
    "    model=XGBRegressor(\n",
    "        n_estimators=20,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "    min_window=60,\n",
    "    step_size=2,\n",
    "    n_splits=5,\n",
    "    cross_val=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.data = predictor.data.iloc[-lookback:, :]\n",
    "df = predictor.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "# seed_everything(42)  # Add at the VERY TOP of the notebook\n",
    "# Prepare models \n",
    "horizon = 20  # 3-week forecast\n",
    "predictor.prepare_models(\n",
    "    predictors=features,\n",
    "    horizon=horizon,\n",
    "    refit=False,  # Note the metrics are the value of the first fit, not the refit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key technical indicators\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Price and Moving Averages\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(df[\"Close\"], label=\"Close Price\")\n",
    "plt.plot(df[\"MA_50\"], label=\"50-day MA\")\n",
    "plt.plot(df[\"MA_200\"], label=\"200-day MA\")\n",
    "plt.title(f\"{symbol} Price and Moving Averages\")\n",
    "plt.legend()\n",
    "\n",
    "# Momentum Indicators\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(df[\"RSI\"], label=\"RSI\", color=\"purple\")\n",
    "plt.plot(df[\"Momentum_Score\"], label=\"Momentum Score\", color=\"orange\")\n",
    "plt.axhline(70, linestyle=\"--\", color=\"red\")\n",
    "plt.axhline(30, linestyle=\"--\", color=\"green\")\n",
    "plt.title(\"Momentum Indicators\")\n",
    "plt.legend()\n",
    "\n",
    "# Volatility\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(df[\"Volatility\"], label=\"Volatility\", color=\"brown\")\n",
    "plt.plot(df[\"ATR\"], label=\"ATR\", color=\"blue\")\n",
    "plt.title(\"Volatility Measures\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Assuming df contains your stock data with columns ['Date', 'Stock_Close']\n",
    "try:\n",
    "    data_FT = predictor.data.reset_index()[[\"Date\", \"Close\"]]\n",
    "except KeyError:\n",
    "    data_FT = predictor.data.reset_index()[[\"Datetime\", \"Close\"]]\n",
    "close_fft = np.fft.fft(np.asarray(data_FT[\"Close\"].tolist()))\n",
    "# Create a DataFrame to store Fourier Transform components\n",
    "fft_df = pd.DataFrame({\"fft\": close_fft})\n",
    "fft_df[\"absolute\"] = fft_df[\"fft\"].apply(lambda x: np.abs(x))\n",
    "fft_df[\"angle\"] = fft_df[\"fft\"].apply(lambda x: np.angle(x))\n",
    "# Plot the inverse Fourier Transforms with different numbers of components\n",
    "plt.figure(figsize=(14, 7), dpi=100)\n",
    "fft_list = np.asarray(fft_df[\"fft\"].tolist())\n",
    "for num_ in [3, 6, 9, 50]:\n",
    "    fft_list_m10 = np.copy(fft_list)\n",
    "    fft_list_m10[num_:-num_] = (\n",
    "        0  # Zero out all but the first and last 'num_' components\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.fft.ifft(fft_list_m10), label=f\"Fourier transform with {num_} components\"\n",
    "    )\n",
    "    print(np.real(np.fft.ifft(fft_list_m10)).shape)\n",
    "\n",
    "plt.plot(data_FT[\"Close\"], label=\"Real\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Stock Prices & Fourier Transforms\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign the Horizon variable      \n",
    "# Make sure prediction_horizon ≤ prepare_models_horizon to avoid data leakage\n",
    "horizon = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type_1 = \"linear\"\n",
    "model_type_2 = \"arimaxgb\"\n",
    "# Generate predictions\n",
    "forecast, backtest, raw_forecast, raw_backtest = predictor.one_step_forward_forecast(\n",
    "    predictors=features, model_type=model_type_1, horizon=horizon\n",
    ")\n",
    "\n",
    "# Generate predictions\n",
    "forecast_arimaxgb, backtest_arimaxgb, raw_forecast_arimaxgb, raw_backtest_arimaxgb = (\n",
    "    predictor.one_step_forward_forecast(\n",
    "        predictors=features, model_type=model_type_2, horizon=horizon\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "from datetime import datetime\n",
    "plt.figure(figsize=(15, 7))\n",
    "if predictor.interval == \"1d\":\n",
    "    first_day = df.index >= pd.to_datetime(date.today()) - pd.Timedelta(days=2*horizon) # Closer to today\n",
    "elif predictor.interval == \"1m\":\n",
    "    first_day = df.index.hour == datetime.today().hour # Closer to today\n",
    "# Training period\n",
    "plt.plot(df[\"Close\"][first_day], label=\"Historical Prices\", color=\"dimgray\", alpha=0.8)\n",
    "\n",
    "# Backtest period\n",
    "backtest_start = df.index[-df.shape[0]]\n",
    "if (backtest[\"Close\"] > 0).all():\n",
    "    plt.plot(\n",
    "        backtest[\"Close\"][first_day], label=\"Backtest\", color=\"blue\", linestyle=\"--\"\n",
    "    )\n",
    "plt.plot(\n",
    "    backtest_arimaxgb[\"Close\"][first_day],\n",
    "    label=\"Backtest_arimaxgb\",\n",
    "    color=\"darkblue\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "# Forecast period\n",
    "forecast_dates = forecast.index[-horizon:]\n",
    "if (backtest[\"Close\"] > 0).all():\n",
    "    plt.plot(\n",
    "        forecast_dates,\n",
    "        forecast[\"Close\"][-horizon:],\n",
    "        label=\"Forecast\",\n",
    "        color=\"green\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "plt.plot(\n",
    "    forecast_dates,\n",
    "    forecast_arimaxgb[\"Close\"][-horizon:],\n",
    "    label=\"Forecast_arimaxgb\",\n",
    "    color=\"darkgreen\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "\n",
    "# Raw model predictions\n",
    "if (backtest[\"Close\"] > 0).all():\n",
    "    plt.plot(\n",
    "        forecast_dates,\n",
    "        raw_forecast[\"Close\"][-horizon:],\n",
    "        label=\"Raw Forecast\",\n",
    "        color=\"lightgreen\",\n",
    "        linestyle=\":\",\n",
    "    )\n",
    "plt.plot(\n",
    "    forecast_dates,\n",
    "    raw_forecast_arimaxgb[\"Close\"][-horizon:],\n",
    "    label=\"Raw Forecast arimaxgb\",\n",
    "    color=\"green\",\n",
    "    linestyle=\":\",\n",
    ")\n",
    "\n",
    "plt.title(f\"{symbol} Price Prediction ({horizon}-day Forecast)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Visualize the log returns\n",
    "plt.figure(figsize=(15, 7))\n",
    "real_backtest_area = backtest_arimaxgb.index >= backtest.index[-horizon-1]\n",
    "plt.plot(\n",
    "    np.log(df[\"Close\"] / df[\"Close\"].shift(1))[real_backtest_area],\n",
    "    label=\"Log Return\",\n",
    "    color=\"purple\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.log(backtest_arimaxgb[\"Close\"] / backtest_arimaxgb[\"Close\"].shift(1))[\n",
    "        real_backtest_area\n",
    "    ],  #  backtest.index[-horizon] is the start of the backtest\n",
    "    label=\"Log Return Backtest Arimaxgb\",\n",
    "    color=\"orange\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.log(backtest[\"Close\"] / backtest[\"Close\"].shift(1))[\n",
    "        real_backtest_area\n",
    "    ],  #  backtest.index[-horizon] is the start of the backtest\n",
    "    label=\"Log Return Backtest Linear\",\n",
    "    color=\"blue\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "plt.axhline(0, linestyle=\"--\", color=\"red\")\n",
    "plt.title(f\"{symbol} Log Returns\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Log Return\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Close', 'ATR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "# Align dates for evaluation\n",
    "eval_start = backtest.iloc[-horizon:].index[0]  # backtest.index[0]\n",
    "actual = df[\"Close\"][df.index >= eval_start]\n",
    "backtest_eval = backtest[\"Close\"][backtest.index >= eval_start]\n",
    "backtest_arimaxgb_eval = backtest_arimaxgb[\"Close\"][\n",
    "    backtest_arimaxgb.index >= eval_start\n",
    "]\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "mape = mean_absolute_percentage_error(actual, backtest_eval)\n",
    "rmse = np.sqrt(mean_squared_error(actual, backtest_eval))\n",
    "r2 = r2_score(y_true=actual, y_pred=backtest_eval)\n",
    "bic = predictor.data.shape[0] * np.log(\n",
    "    np.sum((actual - backtest_eval) ** 2) / predictor.data.shape[0]\n",
    ") + predictor.data.shape[1] * np.log(predictor.data.shape[0])\n",
    "aic = (\n",
    "    predictor.data.shape[0]\n",
    "    * np.log(np.sum((actual - backtest_eval) ** 2) / predictor.data.shape[0])\n",
    "    + predictor.data.shape[1] * 2\n",
    ")\n",
    "\n",
    "mape_arimaxgb = mean_absolute_percentage_error(actual, backtest_arimaxgb_eval)\n",
    "rmse_arimaxgb = np.sqrt(mean_squared_error(actual, backtest_arimaxgb_eval))\n",
    "r2_arimaxgb = r2_score(y_true=actual, y_pred=backtest_arimaxgb_eval)\n",
    "bic_arimaxgb = predictor.data.shape[0] * np.log(\n",
    "    np.sum((actual - backtest_arimaxgb_eval) ** 2) / predictor.data.shape[0]\n",
    ") + predictor.data.shape[1] * np.log(predictor.data.shape[0])\n",
    "aic_arimaxgb = (\n",
    "    predictor.data.shape[0]\n",
    "    * np.log(np.sum((actual - backtest_arimaxgb_eval) ** 2) / predictor.data.shape[0])\n",
    "    + predictor.data.shape[1] * 2\n",
    ")\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"\\nModel Performance Evaluation ({len(actual)} days):\")\n",
    "print(f\"RMSE Linear: {rmse:.2f}\")\n",
    "print(f\"MAPE Linear: {mape:.2%}\")\n",
    "print(f\"BIC Linear: {bic:.2f}\")\n",
    "print(f\"AIC Linear: {aic:.2f}\")\n",
    "# print(f\"R2: {r2:.2f}\")\n",
    "print(\n",
    "    \"if first observation has the correct direction: \",\n",
    "    np.sign(actual.iloc[0] - actual.iloc[1])\n",
    "    == np.sign(backtest_eval.iloc[0] - backtest_eval.iloc[1]),\n",
    ")\n",
    "print(\n",
    "    \"if second observation have the correct direction: \",\n",
    "    np.sign(actual.iloc[0] - actual.iloc[1])\n",
    "    == np.sign(backtest_eval.iloc[0] - backtest_eval.iloc[1]),\n",
    ")\n",
    "print(\n",
    "    \"if last observation has the correct direction: \",\n",
    "    np.sign(actual.iloc[-1] - actual.iloc[-2])\n",
    "    == np.sign(backtest_eval.iloc[-1] - backtest_eval.iloc[-2]),\n",
    ")\n",
    "print(\n",
    "    \"if last second observation have the correct direction: \",\n",
    "    np.sign(actual.iloc[-2] - actual.iloc[-3])\n",
    "    == np.sign(backtest_eval.iloc[-2] - backtest_eval.iloc[-3]),\n",
    ")\n",
    "print(\"\")\n",
    "\n",
    "print(f\"RMSE Arimaxgb: {rmse_arimaxgb:.2f}\")\n",
    "print(f\"MAPE Arimaxgb: {mape_arimaxgb:.2%}\")\n",
    "print(f\"BIC Arimaxgb: {bic_arimaxgb:.2f}\")\n",
    "print(f\"AIC Arimaxgb: {aic_arimaxgb:.2f}\")\n",
    "\n",
    "print(\n",
    "    \"if first observation has the correct direction: \",\n",
    "    np.sign(actual.iloc[0] - actual.iloc[1])\n",
    "    == np.sign(backtest_arimaxgb_eval.iloc[0] - backtest_arimaxgb_eval.iloc[1]),\n",
    ")\n",
    "print(\n",
    "    \"if second observation have the correct direction: \",\n",
    "    np.sign(actual.iloc[0] - actual.iloc[1])\n",
    "    == np.sign(backtest_arimaxgb_eval.iloc[0] - backtest_arimaxgb_eval.iloc[1]),\n",
    ")\n",
    "print(\n",
    "    \"if last observation has the correct direction: \",\n",
    "    np.sign(actual.iloc[-1] - actual.iloc[-2])\n",
    "    == np.sign(backtest_arimaxgb_eval.iloc[-1] - backtest_arimaxgb_eval.iloc[-2]),\n",
    ")\n",
    "print(\n",
    "    \"if last second observation have the correct direction: \",\n",
    "    np.sign(actual.iloc[-2] - actual.iloc[-3])\n",
    "    == np.sign(backtest_arimaxgb_eval.iloc[-2] - backtest_arimaxgb_eval.iloc[-3]),\n",
    ")\n",
    "# print(f\"R2 Arimaxgb: {r2_arimaxgb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis\n",
    "from stock_prediction.utils import feature_importance\n",
    "\n",
    "if hasattr(predictor, \"feature_importances\"):\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    # importance_df = pd.DataFrame(predictor.feature_importances).T\n",
    "    # importance_df = importance_df.sort_values(by='Close', axis=1, ascending=False)\n",
    "    importance_df = feature_importance(\n",
    "        predictor.data.drop(columns=\"Close\"), predictor.data[\"Close\"]\n",
    "    )\n",
    "    display(importance_df)\n",
    "\n",
    "    importance_df.plot(\"Feature\", \"Importance\", kind=\"barh\", figsize=(20, 15))\n",
    "    # plt.xticks(fontsize=5)\n",
    "    # plt.yticks(fontsize=5)\n",
    "    plt.title(\"Feature Importances for Close Price Prediction\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis\n",
    "from stock_prediction.utils import feature_importance\n",
    "\n",
    "if hasattr(predictor, \"feature_importances\"):\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    # importance_df = pd.DataFrame(predictor.feature_importances).T\n",
    "    # importance_df = importance_df.sort_values(by='Close', axis=1, ascending=False)\n",
    "    importance_df_features = feature_importance(\n",
    "        predictor.data[backtest.columns].drop(columns=\"Close\"), predictor.data[\"Close\"]\n",
    "    )\n",
    "    display(importance_df_features)\n",
    "\n",
    "    importance_df_features.plot(\"Feature\", \"Importance\", kind=\"barh\", figsize=(20, 15))\n",
    "    # plt.xticks(fontsize=5)\n",
    "    # plt.yticks(fontsize=5)\n",
    "    plt.title(\"Feature Importances for Close Price Prediction on features\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Details\n",
    "print(\"\\nDetailed Forecast:\")\n",
    "if \"Momentum_Score\" in forecast.columns:\n",
    "    display(forecast[[\"Close\", \"Momentum_Score\"]].tail(horizon))\n",
    "\n",
    "print(\"\\nKey Statistics:\")\n",
    "print(f\"Forecast Range: {forecast_dates[0].date()} to {forecast_dates[-1].date()}\")\n",
    "print(f\"Predicted Change: {(forecast['Close'].iloc[-1]/df['Close'].iloc[-1]-1):.2%}\")\n",
    "print(f\"Predicted Change (Arimaxgb): {(forecast_arimaxgb['Close'].iloc[-1]/df['Close'].iloc[-1]-1):.2%}\")\n",
    "if \"Momentum_Score\" in forecast.columns:\n",
    "    print(f\"Average Momentum Score: {forecast['Momentum_Score'].mean():.2f}\")\n",
    "print(f\"Average Momentum Score (Arimaxgb): {forecast_arimaxgb['Momentum_Score'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Compute residuals\n",
    "residuals = backtest[-horizon:].Close - predictor.data[-horizon:].Close\n",
    "\n",
    "# 1️⃣ Histogram & KDE Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(residuals, kde=True, bins=30)\n",
    "plt.axvline(x=0, color=\"red\", linestyle=\"--\")  # Zero reference line\n",
    "plt.title(\"Residual Distribution\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# 2️⃣ QQ Plot (Quantile-Quantile Plot)\n",
    "plt.figure(figsize=(6, 6))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ Plot of Residuals\")\n",
    "plt.show()\n",
    "\n",
    "# 3️⃣ Statistical Normality Test (Shapiro-Wilk)\n",
    "shapiro_test = stats.shapiro(residuals)\n",
    "print(\n",
    "    f\"Shapiro-Wilk Test: W={shapiro_test.statistic:.4f}, p-value={shapiro_test.pvalue:.4f}\"\n",
    ")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05  # Significance level\n",
    "if shapiro_test.pvalue > alpha:\n",
    "    print(\"Residuals appear to be normally distributed (Fail to reject H0).\")\n",
    "else:\n",
    "    print(\"Residuals are NOT normally distributed (Reject H0).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true_before_backtest = predictor.data[raw_backtest.columns].iloc[-horizon-1].values # Get the last row of the data before backtest\n",
    "\n",
    "# y_pred_first_backtest = raw_backtest.iloc[-horizon].values # Get the first row of the forecast data of original backtest\n",
    "# y_true_first_backtest = predictor.data[raw_backtest.columns].iloc[-horizon].values\n",
    "\n",
    "# y_pred_last_backtest = raw_backtest.iloc[-1].values # Get the first row of the forecast data of original backtest\n",
    "# y_true_last_backtest = predictor.data[raw_backtest.columns].iloc[-1].values\n",
    "\n",
    "\n",
    "# # Compute Up (1) or Down (0) movement of ALL Features\n",
    "# y_true_1d = (y_true_before_backtest > y_true_first_backtest).astype(int)  # 1-day movement\n",
    "# y_pred_1d = (y_true_before_backtest > y_pred_first_backtest ).astype(int)\n",
    "# y_true_horizon = (y_true_before_backtest > y_true_last_backtest).astype(int)\n",
    "# y_pred_horizon = (y_true_before_backtest > y_pred_last_backtest).astype(int)\n",
    "\n",
    "\n",
    "y_true = np.sign(\n",
    "    predictor.data[raw_backtest.columns].iloc[-horizon - 1 :].Close.diff().dropna()\n",
    ")  # Convert to Up/Down movement\n",
    "y_pred = np.sign(\n",
    "    raw_backtest.iloc[-horizon - 1 :].Close.diff().dropna()\n",
    ")  # Convert predictions to Up/Down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtester and StressTester\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_market_calendars as mcal\n",
    "import pandas as pd\n",
    "# nyse = mcal.get_calendar(\"NYSE\").schedule(\n",
    "#    start_date=\"2020-01-01\", end_date=\"2023-12-01\"\n",
    "# ).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"CRWD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_prediction.core import Backtester, StockPredictor\n",
    "\n",
    "predictor = StockPredictor(symbol, start_date=\"2023-06-15\", interval=\"1d\")\n",
    "predictor.load_data()\n",
    "# backtester = Backtester(predictor)\n",
    "# print(backtester.portfolio)\n",
    "# history, report = backtester.run_backtest(\"2023-01-03\", \"2023-01-09\")\n",
    "# print(backtester.portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stock_prediction.core import StockPredictor\n",
    "# StockPredictor.create_hqm_stocks(start_date= \"2021-01-01\", end_date=\"2023-01-01\").head(10).Symbol.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = Backtester(predictor)\n",
    "start_date = \"2025-01-01\"\n",
    "end_date = \"2025-05-05\"\n",
    "# Run backtest\n",
    "history, report = bt.run_backtest(\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of BUY:',len([order for order in bt.portfolio[\"transactions\"] if order[0] == \"BUY\"]))\n",
    "\n",
    "print('Number of SELL:', len([order for order in bt.portfolio[\"transactions\"] if order[0] == \"SELL\"]))\n",
    "nyse = mcal.get_calendar(\"NYSE\").schedule(\n",
    "    start_date=start_date, end_date=end_date\n",
    ").index\n",
    "print('Number of trading days:', len(nyse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(history['value'].diff().dropna()>0).astype(int).sum()/report['num_trades']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report\n",
    "# save the report to a txt file in the dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import yfinance as yf\n",
    "from stock_prediction.utils import  get_next_valid_date\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(yf.download(symbol, start=start_date, end=get_next_valid_date(end_date), interval='1d').Close)\n",
    "plt.title(f\"{symbol} Price\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(\n",
    "history['value'])\n",
    "plt.title(\"Portfolio Value Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "# Load data into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Portfolio_Return': history['value'].pct_change().dropna().values,\n",
    "   'Stock_Return': yf.download(symbol, start=start_date, end=get_next_valid_date(end_date), interval='1d')[\"Close\"].pct_change().dropna()[symbol].values\n",
    "})\n",
    "\n",
    "# Calculate covariance matrix\n",
    "covariance_matrix = df.cov()\n",
    "covariance = covariance_matrix.iloc[0, 1]\n",
    "\n",
    "# Calculate variance of stock returns\n",
    "variance = df['Stock_Return'].var()\n",
    "\n",
    "# Beta\n",
    "beta = covariance / variance\n",
    "print(beta)  # Output: ~0.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# de-annualize yearly interest rates\n",
    "def deannualize(annual_rate, periods=365):\n",
    "    return (1 + annual_rate) ** (1/periods) - 1\n",
    "\n",
    "def get_risk_free_rate():\n",
    "    # download 3-month us treasury bills rates\n",
    "    annualized = yf.download(\"^IRX\")[\"Close\"]\n",
    "    \n",
    "    # de-annualize\n",
    "    daily = annualized.apply(deannualize)\n",
    "\n",
    "    # create dataframe\n",
    "    return pd.DataFrame({\"annualized\": annualized[\"^IRX\"].values, \"daily\": daily[\"^IRX\"].values})    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk-free rate \n",
    "get_risk_free_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report[\"total_return\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stock_prediction.core import StressTester\n",
    "# stress_tester = StressTester(predictor)\n",
    "# stress_tester.portfolio\n",
    "# stress_history, stress_report = stress_tester.run_stress_test(start_date=start_date, end_date=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stress_history['value'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook-header",
   "metadata": {},
   "source": [
    "# Comprehensive ML Models Comparison: Loss vs Epoch Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook provides a comprehensive comparison of 10+ machine learning models for stock price prediction, with detailed loss vs epoch tracking and analysis.\n",
    "\n",
    "### Models Included:\n",
    "**Linear Models:** Ridge, Lasso, ElasticNet, Huber Regressor  \n",
    "**Ensemble Models:** Random Forest, Gradient Boosting, XGBoost, LightGBM  \n",
    "**Neural Networks:** MLPRegressor  \n",
    "**Support Vector Regression:** SVR  \n",
    "**Custom Models:** GradientDescentRegressor, SGDRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ml-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning imports\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, HuberRegressor, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Additional ML libraries\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not available\")\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "    print(\"LightGBM not available\")\n",
    "\n",
    "# Stock prediction imports\n",
    "from stock_prediction import StockPredictor\n",
    "from stock_prediction.core import GradientDescentRegressor\n",
    "\n",
    "print(\"ML libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare stock data\n",
    "print(\"Loading stock data...\")\n",
    "stock = StockPredictor(\"AAPL\", \"2018-01-01\")\n",
    "stock.load_data()\n",
    "stock_data = stock.data\n",
    "\n",
    "print(f\"Data loaded successfully: {stock_data.shape[0]} rows, {stock_data.shape[1]} columns\")\n",
    "print(f\"Date range: {stock_data.index[0]} to {stock_data.index[-1]}\")\n",
    "\n",
    "# Prepare features and target\n",
    "X = stock_data.drop(columns=\"Close\")\n",
    "y = stock_data[\"Close\"]\n",
    "\n",
    "# Split data\n",
    "train_pct_index = int(0.7 * len(X))\n",
    "X_train, X_test = X[:train_pct_index], X[train_pct_index:]\n",
    "y_train, y_test = y[:train_pct_index], y[train_pct_index:]\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for compatibility\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
    "\n",
    "print(\"Data preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration Section\n",
    "print(\"Configuring models...\")\n",
    "\n",
    "# Initialize models dictionary\n",
    "models_config = {}\n",
    "\n",
    "# Linear Models\n",
    "models_config['Ridge'] = Ridge(alpha=1.0, random_state=42)\n",
    "models_config['Lasso'] = Lasso(alpha=0.1, random_state=42, max_iter=2000)\n",
    "models_config['ElasticNet'] = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42, max_iter=2000)\n",
    "models_config['Huber'] = HuberRegressor(epsilon=1.35, max_iter=1000)\n",
    "models_config['SGD'] = SGDRegressor(random_state=42, max_iter=1000)\n",
    "\n",
    "# Ensemble Models\n",
    "models_config['RandomForest'] = RandomForestRegressor(n_estimators=100, random_state=42, warm_start=True)\n",
    "models_config['GradientBoosting'] = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Add XGBoost if available\n",
    "if XGBOOST_AVAILABLE:\n",
    "    models_config['XGBoost'] = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Add LightGBM if available\n",
    "if LIGHTGBM_AVAILABLE:\n",
    "    models_config['LightGBM'] = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42, verbose=-1)\n",
    "\n",
    "# Neural Networks\n",
    "models_config['MLP'] = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1, random_state=42, warm_start=True)\n",
    "\n",
    "# Support Vector Regression\n",
    "models_config['SVR'] = SVR(kernel='rbf', C=1.0)\n",
    "\n",
    "# Custom Models\n",
    "models_config['Custom_GD'] = GradientDescentRegressor(n_iter=1000, lr=0.01, random_state=42)\n",
    "\n",
    "print(f\"Configured {len(models_config)} models for comparison:\")\n",
    "for name in models_config.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loss-tracking-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart Loss Tracking Functions\n",
    "\n",
    "def track_loss_partial_fit(model, X_train, y_train, X_test, y_test, model_name, max_epochs=100):\n",
    "    \"\"\"Track loss for models with partial_fit capability\"\"\"\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # Create chunks for incremental learning\n",
    "    chunk_size = max(1, len(X_train) // 10)\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        # Train on random chunk\n",
    "        idx = np.random.choice(len(X_train), chunk_size, replace=False)\n",
    "        X_chunk = X_train.iloc[idx] if hasattr(X_train, 'iloc') else X_train[idx]\n",
    "        y_chunk = y_train.iloc[idx] if hasattr(y_train, 'iloc') else y_train[idx]\n",
    "        \n",
    "        # Partial fit\n",
    "        model.partial_fit(X_chunk, y_chunk)\n",
    "        \n",
    "        # Calculate losses\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_loss = mean_squared_error(y_train, train_pred)\n",
    "        test_loss = mean_squared_error(y_test, test_pred)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if epoch > 10 and len(test_losses) > 5:\n",
    "            if np.mean(test_losses[-5:]) > np.mean(test_losses[-10:-5]):\n",
    "                print(f\"Early stopping for {model_name} at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    return train_losses, test_losses\n",
    "\n",
    "def track_loss_warm_start(model, X_train, y_train, X_test, y_test, model_name, max_estimators=100):\n",
    "    \"\"\"Track loss for ensemble models with warm_start\"\"\"\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # Progressively increase n_estimators\n",
    "    for n_est in range(10, max_estimators + 1, 10):\n",
    "        model.n_estimators = n_est\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Calculate losses\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_loss = mean_squared_error(y_train, train_pred)\n",
    "        test_loss = mean_squared_error(y_test, test_pred)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "    return train_losses, test_losses\n",
    "\n",
    "def track_loss_progressive_training(model, X_train, y_train, X_test, y_test, model_name, max_epochs=50):\n",
    "    \"\"\"Track loss using progressive training with increasing data subsets\"\"\"\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # Progressive training with increasing data size\n",
    "    min_size = max(50, len(X_train) // 10)\n",
    "    step_size = (len(X_train) - min_size) // max_epochs\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        # Determine training size for this epoch\n",
    "        train_size = min_size + epoch * step_size\n",
    "        train_size = min(train_size, len(X_train))\n",
    "        \n",
    "        # Train on subset\n",
    "        X_subset = X_train.iloc[:train_size] if hasattr(X_train, 'iloc') else X_train[:train_size]\n",
    "        y_subset = y_train.iloc[:train_size] if hasattr(y_train, 'iloc') else y_train[:train_size]\n",
    "        \n",
    "        model.fit(X_subset, y_subset)\n",
    "        \n",
    "        # Calculate losses\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_loss = mean_squared_error(y_train, train_pred)\n",
    "        test_loss = mean_squared_error(y_test, test_pred)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "    return train_losses, test_losses\n",
    "\n",
    "def track_loss_custom_gd(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"Track loss for custom gradient descent model\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get loss history from model\n",
    "    train_losses = model.mse_history if hasattr(model, 'mse_history') else []\n",
    "    \n",
    "    # Calculate test losses for each epoch\n",
    "    test_losses = []\n",
    "    if hasattr(model, 'coef_history') and model.coef_history:\n",
    "        for coef in model.coef_history:\n",
    "            # Simulate prediction with historical coefficients\n",
    "            test_pred = X_test @ coef[1:] + coef[0]  # Assuming coef[0] is intercept\n",
    "            test_loss = mean_squared_error(y_test, test_pred)\n",
    "            test_losses.append(test_loss)\n",
    "    else:\n",
    "        # Fallback: use final test loss for all epochs\n",
    "        test_pred = model.predict(X_test)\n",
    "        test_loss = mean_squared_error(y_test, test_pred)\n",
    "        test_losses = [test_loss] * len(train_losses)\n",
    "    \n",
    "    return train_losses, test_losses\n",
    "\n",
    "print(\"Loss tracking functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-training-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Training Loop with Progress Tracking\n",
    "print(\"Starting comprehensive model training and comparison...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize results dictionary\n",
    "model_results = {\n",
    "    'model_name': [],\n",
    "    'train_losses': [],\n",
    "    'test_losses': [],\n",
    "    'best_epoch': [],\n",
    "    'final_train_mse': [],\n",
    "    'final_test_mse': [],\n",
    "    'training_time': [],\n",
    "    'r2_score': [],\n",
    "    'mae': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "for model_name, model in tqdm(models_config.items(), desc=\"Training Models\"):\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    start_time = time()\n",
    "    \n",
    "    try:\n",
    "        # Determine training strategy based on model type\n",
    "        if model_name == 'Custom_GD':\n",
    "            train_losses, test_losses = track_loss_custom_gd(\n",
    "                model, X_train_scaled, y_train, X_test_scaled, y_test, model_name\n",
    "            )\n",
    "        elif model_name == 'SGD':\n",
    "            train_losses, test_losses = track_loss_partial_fit(\n",
    "                model, X_train_scaled, y_train, X_test_scaled, y_test, model_name\n",
    "            )\n",
    "        elif model_name in ['RandomForest', 'GradientBoosting'] and hasattr(model, 'warm_start'):\n",
    "            train_losses, test_losses = track_loss_warm_start(\n",
    "                model, X_train_scaled, y_train, X_test_scaled, y_test, model_name\n",
    "            )\n",
    "        elif model_name == 'MLP':\n",
    "            # Special handling for MLP with warm_start\n",
    "            train_losses, test_losses = [], []\n",
    "            for epoch in range(100):\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                train_pred = model.predict(X_train_scaled)\n",
    "                test_pred = model.predict(X_test_scaled)\n",
    "                train_losses.append(mean_squared_error(y_train, train_pred))\n",
    "                test_losses.append(mean_squared_error(y_test, test_pred))\n",
    "                \n",
    "                # Early stopping for MLP\n",
    "                if epoch > 10 and len(test_losses) > 5:\n",
    "                    if np.mean(test_losses[-5:]) > np.mean(test_losses[-10:-5]):\n",
    "                        break\n",
    "        else:\n",
    "            # Progressive training for other models\n",
    "            train_losses, test_losses = track_loss_progressive_training(\n",
    "                model, X_train_scaled, y_train, X_test_scaled, y_test, model_name\n",
    "            )\n",
    "        \n",
    "        # Final model training on full dataset\n",
    "        if model_name != 'Custom_GD':  # Custom GD already trained\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Calculate final metrics\n",
    "        final_train_pred = model.predict(X_train_scaled)\n",
    "        final_test_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        final_train_mse = mean_squared_error(y_train, final_train_pred)\n",
    "        final_test_mse = mean_squared_error(y_test, final_test_pred)\n",
    "        r2 = r2_score(y_test, final_test_pred)\n",
    "        mae = mean_absolute_error(y_test, final_test_pred)\n",
    "        \n",
    "        # Find best epoch\n",
    "        best_epoch = np.argmin(test_losses) if test_losses else 0\n",
    "        \n",
    "        # Record results\n",
    "        training_time = time() - start_time\n",
    "        \n",
    "        model_results['model_name'].append(model_name)\n",
    "        model_results['train_losses'].append(train_losses)\n",
    "        model_results['test_losses'].append(test_losses)\n",
    "        model_results['best_epoch'].append(best_epoch)\n",
    "        model_results['final_train_mse'].append(final_train_mse)\n",
    "        model_results['final_test_mse'].append(final_test_mse)\n",
    "        model_results['training_time'].append(training_time)\n",
    "        model_results['r2_score'].append(r2)\n",
    "        model_results['mae'].append(mae)\n",
    "        \n",
    "        print(f\"  ‚úì {model_name} completed in {training_time:.2f}s\")\n",
    "        print(f\"    Final Test MSE: {final_test_mse:.4f}, R¬≤: {r2:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó {model_name} failed: {str(e)}\")\n",
    "        # Add placeholder results for failed models\n",
    "        model_results['model_name'].append(model_name)\n",
    "        model_results['train_losses'].append([])\n",
    "        model_results['test_losses'].append([])\n",
    "        model_results['best_epoch'].append(0)\n",
    "        model_results['final_train_mse'].append(np.inf)\n",
    "        model_results['final_test_mse'].append(np.inf)\n",
    "        model_results['training_time'].append(time() - start_time)\n",
    "        model_results['r2_score'].append(-np.inf)\n",
    "        model_results['mae'].append(np.inf)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Model training completed!\")\n",
    "print(f\"Successfully trained {len([r for r in model_results['final_test_mse'] if r != np.inf])} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Summary Table\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': model_results['model_name'],\n",
    "    'Final_Train_MSE': model_results['final_train_mse'],\n",
    "    'Final_Test_MSE': model_results['final_test_mse'],\n",
    "    'R¬≤_Score': model_results['r2_score'],\n",
    "    'MAE': model_results['mae'],\n",
    "    'Best_Epoch': model_results['best_epoch'],\n",
    "    'Training_Time(s)': model_results['training_time']\n",
    "})\n",
    "\n",
    "# Filter out failed models\n",
    "summary_df = summary_df[summary_df['Final_Test_MSE'] != np.inf]\n",
    "\n",
    "# Sort by test MSE (best performance first)\n",
    "summary_df = summary_df.sort_values('Final_Test_MSE')\n",
    "\n",
    "# Display formatted table\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Highlight best performing models\n",
    "best_model = summary_df.iloc[0]\n",
    "print(f\"\\nüèÜ BEST PERFORMING MODEL: {best_model['Model']}\")\n",
    "print(f\"   Test MSE: {best_model['Final_Test_MSE']:.4f}\")\n",
    "print(f\"   R¬≤ Score: {best_model['R¬≤_Score']:.4f}\")\n",
    "print(f\"   Training Time: {best_model['Training_Time(s)']:.2f}s\")\n",
    "\n",
    "# Performance rankings\n",
    "print(\"\\nüìä MODEL RANKINGS (by Test MSE):\")\n",
    "for i, (idx, row) in enumerate(summary_df.iterrows(), 1):\n",
    "    print(f\"   {i}. {row['Model']} - MSE: {row['Final_Test_MSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Visualizations - Main Comparison Plot\n",
    "print(\"Creating comprehensive visualizations...\")\n",
    "\n",
    "# Set up the plot style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(model_results['model_name'])))\n",
    "\n",
    "# Main comparison plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Training Loss Curves\n",
    "ax1.set_title('Training Loss Curves - All Models', fontsize=16, fontweight='bold')\n",
    "for i, (model_name, train_losses) in enumerate(zip(model_results['model_name'], model_results['train_losses'])):\n",
    "    if train_losses and len(train_losses) > 1:\n",
    "        epochs = range(1, len(train_losses) + 1)\n",
    "        ax1.plot(epochs, train_losses, label=model_name, color=colors[i], linewidth=2, alpha=0.8)\n",
    "        \n",
    "        # Mark best epoch\n",
    "        best_idx = model_results['best_epoch'][i]\n",
    "        if best_idx < len(train_losses):\n",
    "            ax1.scatter(best_idx + 1, train_losses[best_idx], color=colors[i], s=100, marker='*', \n",
    "                       edgecolor='black', linewidth=1, zorder=5)\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Training MSE', fontsize=12)\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# Plot 2: Test Loss Curves\n",
    "ax2.set_title('Test Loss Curves - All Models', fontsize=16, fontweight='bold')\n",
    "for i, (model_name, test_losses) in enumerate(zip(model_results['model_name'], model_results['test_losses'])):\n",
    "    if test_losses and len(test_losses) > 1:\n",
    "        epochs = range(1, len(test_losses) + 1)\n",
    "        ax2.plot(epochs, test_losses, label=model_name, color=colors[i], linewidth=2, alpha=0.8)\n",
    "        \n",
    "        # Mark best epoch\n",
    "        best_idx = model_results['best_epoch'][i]\n",
    "        if best_idx < len(test_losses):\n",
    "            ax2.scatter(best_idx + 1, test_losses[best_idx], color=colors[i], s=100, marker='*', \n",
    "                       edgecolor='black', linewidth=1, zorder=5)\n",
    "\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Test MSE', fontsize=12)\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Main comparison plots created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-model-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Model Category Plots\n",
    "print(\"Creating individual model category plots...\")\n",
    "\n",
    "# Categorize models\n",
    "categories = {\n",
    "    'Linear Models': ['Ridge', 'Lasso', 'ElasticNet', 'Huber', 'SGD'],\n",
    "    'Ensemble Models': ['RandomForest', 'GradientBoosting', 'XGBoost', 'LightGBM'],\n",
    "    'Advanced Models': ['MLP', 'SVR', 'Custom_GD']\n",
    "}\n",
    "\n",
    "# Create subplots for each category\n",
    "fig, axes = plt.subplots(len(categories), 1, figsize=(15, 6 * len(categories)))\n",
    "if len(categories) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for cat_idx, (category, model_names) in enumerate(categories.items()):\n",
    "    ax = axes[cat_idx]\n",
    "    ax.set_title(f'{category} - Loss Comparison', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Plot models in this category\n",
    "    for model_name in model_names:\n",
    "        if model_name in model_results['model_name']:\n",
    "            idx = model_results['model_name'].index(model_name)\n",
    "            train_losses = model_results['train_losses'][idx]\n",
    "            test_losses = model_results['test_losses'][idx]\n",
    "            \n",
    "            if train_losses and test_losses:\n",
    "                epochs = range(1, min(len(train_losses), len(test_losses)) + 1)\n",
    "                if epochs:\n",
    "                    ax.plot(epochs, train_losses[:len(epochs)], '--', label=f'{model_name} (Train)', alpha=0.7)\n",
    "                    ax.plot(epochs, test_losses[:len(epochs)], '-', label=f'{model_name} (Test)', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('MSE')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Individual category plots created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance-analysis-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Analysis Plots\n",
    "print(\"Creating performance analysis plots...\")\n",
    "\n",
    "# Filter out failed models for analysis\n",
    "valid_models = summary_df.copy()\n",
    "\n",
    "# Create comprehensive analysis plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Test MSE Comparison\n",
    "ax1 = axes[0, 0]\n",
    "bars1 = ax1.bar(valid_models['Model'], valid_models['Final_Test_MSE'], \n",
    "                color='lightcoral', alpha=0.7, edgecolor='black')\n",
    "ax1.set_title('Final Test MSE by Model', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Test MSE')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight best model\n",
    "bars1[0].set_color('gold')\n",
    "bars1[0].set_edgecolor('orange')\n",
    "bars1[0].set_linewidth(2)\n",
    "\n",
    "# 2. R¬≤ Score Comparison\n",
    "ax2 = axes[0, 1]\n",
    "bars2 = ax2.bar(valid_models['Model'], valid_models['R¬≤_Score'], \n",
    "                color='lightblue', alpha=0.7, edgecolor='black')\n",
    "ax2.set_title('R¬≤ Score by Model', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('R¬≤ Score')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight best R¬≤ score\n",
    "best_r2_idx = valid_models['R¬≤_Score'].idxmax()\n",
    "best_r2_pos = valid_models.index.get_loc(best_r2_idx)\n",
    "bars2[best_r2_pos].set_color('lightgreen')\n",
    "bars2[best_r2_pos].set_edgecolor('darkgreen')\n",
    "bars2[best_r2_pos].set_linewidth(2)\n",
    "\n",
    "# 3. Training Time vs Performance\n",
    "ax3 = axes[1, 0]\n",
    "scatter = ax3.scatter(valid_models['Training_Time(s)'], valid_models['Final_Test_MSE'], \n",
    "                     c=valid_models['R¬≤_Score'], cmap='viridis', s=100, alpha=0.7, \n",
    "                     edgecolor='black', linewidth=1)\n",
    "ax3.set_title('Training Time vs Performance', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Training Time (seconds)')\n",
    "ax3.set_ylabel('Test MSE')\n",
    "ax3.set_yscale('log')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax3)\n",
    "cbar.set_label('R¬≤ Score')\n",
    "\n",
    "# Add annotations for notable models\n",
    "for idx, row in valid_models.iterrows():\n",
    "    ax3.annotate(row['Model'], (row['Training_Time(s)'], row['Final_Test_MSE']), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.8)\n",
    "\n",
    "# 4. Performance Ranking\n",
    "ax4 = axes[1, 1]\n",
    "ranking_data = valid_models.sort_values('Final_Test_MSE').head(8)\n",
    "bars4 = ax4.barh(range(len(ranking_data)), ranking_data['Final_Test_MSE'], \n",
    "                 color='lightsteelblue', alpha=0.7, edgecolor='black')\n",
    "ax4.set_title('Top 8 Models by Test MSE', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('Test MSE')\n",
    "ax4.set_yticks(range(len(ranking_data)))\n",
    "ax4.set_yticklabels(ranking_data['Model'])\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight top 3\n",
    "for i in range(min(3, len(bars4))):\n",
    "    bars4[i].set_color(['gold', 'silver', 'brown'][i])\n",
    "    bars4[i].set_alpha(0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Performance analysis plots created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convergence-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence Behavior Analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONVERGENCE BEHAVIOR ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Analyze convergence patterns\n",
    "convergence_analysis = []\n",
    "\n",
    "for i, model_name in enumerate(model_results['model_name']):\n",
    "    test_losses = model_results['test_losses'][i]\n",
    "    \n",
    "    if test_losses and len(test_losses) > 5:\n",
    "        # Calculate convergence metrics\n",
    "        final_loss = test_losses[-1]\n",
    "        min_loss = min(test_losses)\n",
    "        best_epoch = test_losses.index(min_loss)\n",
    "        \n",
    "        # Convergence speed (epochs to reach 95% of final performance)\n",
    "        target_loss = min_loss * 1.05\n",
    "        convergence_epoch = 0\n",
    "        for epoch, loss in enumerate(test_losses):\n",
    "            if loss <= target_loss:\n",
    "                convergence_epoch = epoch\n",
    "                break\n",
    "        \n",
    "        # Stability (variance in last 10 epochs)\n",
    "        stability = np.var(test_losses[-10:]) if len(test_losses) >= 10 else np.var(test_losses)\n",
    "        \n",
    "        # Overfitting indicator (test loss increase after min)\n",
    "        overfitting = (final_loss - min_loss) / min_loss if min_loss > 0 else 0\n",
    "        \n",
    "        convergence_analysis.append({\n",
    "            'Model': model_name,\n",
    "            'Min_Loss': min_loss,\n",
    "            'Final_Loss': final_loss,\n",
    "            'Best_Epoch': best_epoch,\n",
    "            'Convergence_Speed': convergence_epoch,\n",
    "            'Stability': stability,\n",
    "            'Overfitting_Ratio': overfitting\n",
    "        })\n",
    "\n",
    "if convergence_analysis:\n",
    "    conv_df = pd.DataFrame(convergence_analysis)\n",
    "    conv_df = conv_df.sort_values('Min_Loss')\n",
    "    \n",
    "    print(\"\\nConvergence Analysis Summary:\")\n",
    "    print(conv_df.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Identify best converging models\n",
    "    fast_convergers = conv_df.nsmallest(3, 'Convergence_Speed')\n",
    "    stable_models = conv_df.nsmallest(3, 'Stability')\n",
    "    \n",
    "    print(f\"\\nüöÄ FASTEST CONVERGING MODELS:\")\n",
    "    for _, row in fast_convergers.iterrows():\n",
    "        print(f\"   {row['Model']} - Converged in {row['Convergence_Speed']} epochs\")\n",
    "    \n",
    "    print(f\"\\nüéØ MOST STABLE MODELS:\")\n",
    "    for _, row in stable_models.iterrows():\n",
    "        print(f\"   {row['Model']} - Stability: {row['Stability']:.6f}\")\n",
    "else:\n",
    "    print(\"Insufficient data for convergence analysis.\")\n",
    "\n",
    "print(\"\\nConvergence analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recommendations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations for Stock Prediction\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECOMMENDATIONS FOR STOCK PREDICTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get top performing models\n",
    "top_models = summary_df.head(5)\n",
    "\n",
    "print(\"\\nüìà TOP RECOMMENDATIONS:\")\n",
    "print(\"\\n1. BEST OVERALL PERFORMANCE:\")\n",
    "best_model = top_models.iloc[0]\n",
    "print(f\"   Model: {best_model['Model']}\")\n",
    "print(f\"   Test MSE: {best_model['Final_Test_MSE']:.4f}\")\n",
    "print(f\"   R¬≤ Score: {best_model['R¬≤_Score']:.4f}\")\n",
    "print(f\"   Why: Achieves the lowest test error with good generalization\")\n",
    "\n",
    "print(\"\\n2. BEST BALANCE (Performance vs Speed):\")\n",
    "# Calculate efficiency score (inverse of MSE * time)\n",
    "efficiency_scores = 1 / (summary_df['Final_Test_MSE'] * summary_df['Training_Time(s)'])\n",
    "best_efficiency_idx = efficiency_scores.idxmax()\n",
    "efficient_model = summary_df.loc[best_efficiency_idx]\n",
    "print(f\"   Model: {efficient_model['Model']}\")\n",
    "print(f\"   Test MSE: {efficient_model['Final_Test_MSE']:.4f}\")\n",
    "print(f\"   Training Time: {efficient_model['Training_Time(s)']:.2f}s\")\n",
    "print(f\"   Why: Best trade-off between accuracy and computational efficiency\")\n",
    "\n",
    "print(\"\\n3. FASTEST TRAINING:\")\n",
    "fastest_model = summary_df.loc[summary_df['Training_Time(s)'].idxmin()]\n",
    "print(f\"   Model: {fastest_model['Model']}\")\n",
    "print(f\"   Training Time: {fastest_model['Training_Time(s)']:.2f}s\")\n",
    "print(f\"   Test MSE: {fastest_model['Final_Test_MSE']:.4f}\")\n",
    "print(f\"   Why: Ideal for high-frequency trading or real-time applications\")\n",
    "\n",
    "print(\"\\nüìä ANALYSIS INSIGHTS:\")\n",
    "\n",
    "# Model type analysis\n",
    "linear_models = ['Ridge', 'Lasso', 'ElasticNet', 'Huber', 'SGD']\n",
    "ensemble_models = ['RandomForest', 'GradientBoosting', 'XGBoost', 'LightGBM']\n",
    "advanced_models = ['MLP', 'SVR', 'Custom_GD']\n",
    "\n",
    "def analyze_category(models, category_name):\n",
    "    category_results = summary_df[summary_df['Model'].isin(models)]\n",
    "    if not category_results.empty:\n",
    "        avg_mse = category_results['Final_Test_MSE'].mean()\n",
    "        avg_time = category_results['Training_Time(s)'].mean()\n",
    "        best_in_category = category_results.loc[category_results['Final_Test_MSE'].idxmin(), 'Model']\n",
    "        return avg_mse, avg_time, best_in_category\n",
    "    return None, None, None\n",
    "\n",
    "linear_mse, linear_time, best_linear = analyze_category(linear_models, 'Linear')\n",
    "ensemble_mse, ensemble_time, best_ensemble = analyze_category(ensemble_models, 'Ensemble')\n",
    "advanced_mse, advanced_time, best_advanced = analyze_category(advanced_models, 'Advanced')\n",
    "\n",
    "print(\"\\n‚Ä¢ LINEAR MODELS:\")\n",
    "if linear_mse is not None:\n",
    "    print(f\"   Average MSE: {linear_mse:.4f}, Average Time: {linear_time:.2f}s\")\n",
    "    print(f\"   Best: {best_linear} - Good for interpretability and fast training\")\n",
    "\n",
    "print(\"\\n‚Ä¢ ENSEMBLE MODELS:\")\n",
    "if ensemble_mse is not None:\n",
    "    print(f\"   Average MSE: {ensemble_mse:.4f}, Average Time: {ensemble_time:.2f}s\")\n",
    "    print(f\"   Best: {best_ensemble} - Excellent for capturing complex patterns\")\n",
    "\n",
    "print(\"\\n‚Ä¢ ADVANCED MODELS:\")\n",
    "if advanced_mse is not None:\n",
    "    print(f\"   Average MSE: {advanced_mse:.4f}, Average Time: {advanced_time:.2f}s\")\n",
    "    print(f\"   Best: {best_advanced} - Specialized for non-linear relationships\")\n",
    "\n",
    "print(\"\\nüéØ PRACTICAL RECOMMENDATIONS:\")\n",
    "print(\"\\n‚Ä¢ For PRODUCTION systems: Use top 3 models in ensemble\")\n",
    "print(\"‚Ä¢ For RESEARCH: Focus on models with best R¬≤ scores\")\n",
    "print(\"‚Ä¢ For REAL-TIME trading: Prioritize fastest models with acceptable accuracy\")\n",
    "print(\"‚Ä¢ For INTERPRETABILITY: Use linear models (Ridge, Lasso)\")\n",
    "print(\"‚Ä¢ For MAXIMUM ACCURACY: Use ensemble methods or custom GD\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT CONSIDERATIONS:\")\n",
    "print(\"‚Ä¢ Stock prediction is inherently challenging due to market volatility\")\n",
    "print(\"‚Ä¢ Model performance may vary significantly with different time periods\")\n",
    "print(\"‚Ä¢ Consider ensemble methods combining multiple top models\")\n",
    "print(\"‚Ä¢ Regular retraining is essential for maintaining performance\")\n",
    "print(\"‚Ä¢ Risk management should always accompany prediction models\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPREHENSIVE ANALYSIS COMPLETED!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This comprehensive analysis has successfully compared 10+ machine learning models for stock price prediction with detailed loss tracking and performance analysis. \n",
    "\n",
    "### Key Findings:\n",
    "1. **Model Performance**: Different models show varying convergence patterns and final performance\n",
    "2. **Training Efficiency**: Significant trade-offs exist between accuracy and computational speed\n",
    "3. **Convergence Behavior**: Some models converge faster while others are more stable\n",
    "4. **Practical Applications**: Model selection depends on specific use case requirements\n",
    "\n",
    "### Technical Achievements:\n",
    "- ‚úÖ Implemented smart loss tracking for different model types\n",
    "- ‚úÖ Added comprehensive performance metrics and analysis\n",
    "- ‚úÖ Created professional visualizations for model comparison\n",
    "- ‚úÖ Provided actionable recommendations for stock prediction\n",
    "- ‚úÖ Included error handling and robust training procedures\n",
    "\n",
    "This analysis provides a solid foundation for selecting and implementing machine learning models for stock price prediction in production environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}